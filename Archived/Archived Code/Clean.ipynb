{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "\n",
    "ox.settings.log_console=True\n",
    "\n",
    "map_graph = ox.graph_from_place('Burgos, Spain', network_type='drive')\n",
    "largest_cc = max(nx.strongly_connected_components(map_graph), key=len)\n",
    "map_graph = map_graph.subgraph(largest_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_element_similarity(G,T):\n",
    "    M=np.zeros((len(T),len(T)))\n",
    "    G_aux=G.copy()\n",
    "\n",
    "    for i,track_i in enumerate(T):\n",
    "        for j,track_j in enumerate(T):\n",
    "            if i==j:\n",
    "                continue\n",
    "\n",
    "            G_aux.add_node(\"vSource\")\n",
    "            for n in track_i:\n",
    "                G_aux.add_edge(\"vSource\",n,length=0) #NOT EQUAL TO: n,\"vSource\" (directed)\n",
    "            dists=[nx.shortest_path_length(G_aux,\"vSource\",m, weight='length') for m in track_j]\n",
    "            G_aux.remove_node(\"vSource\")\n",
    "\n",
    "            M[i,j]=sum(dists)/len(track_i)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_element_similarity_v2(G,T):\n",
    "    M=np.zeros((len(T),len(T)))\n",
    "    G_aux=G.copy()\n",
    "\n",
    "    for i,track_i in enumerate(T):\n",
    "        for j,track_j in enumerate(T):\n",
    "            if i==j:\n",
    "                continue\n",
    "\n",
    "            G_aux.add_node(\"vSource\")\n",
    "            G_aux.add_edges_from((\"vSource\", n, {'length': 0}) for n in track_i)\n",
    "            dists=[nx.shortest_path_length(G_aux,\"vSource\",m, weight='length') for m in track_j]\n",
    "            G_aux.remove_node(\"vSource\")\n",
    "\n",
    "            M[i,j]=sum(dists)/len(track_i)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROW-TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_wise_track_similarity(G,T):\n",
    "    M=np.zeros((len(T),len(T)))\n",
    "    G_aux=G.copy()\n",
    "\n",
    "    for i,track_i in enumerate(T):\n",
    "\n",
    "        G_aux.add_node(\"vSource\")\n",
    "        G_aux.add_edges_from((\"vSource\", n, {'length': 0}) for n in track_i)\n",
    "        dists=nx.single_source_shortest_path_length(G_aux,\"vSource\")\n",
    "        G_aux.remove_node(\"vSource\")\n",
    "\n",
    "        for j,track_j in enumerate(T):\n",
    "            if i==j:\n",
    "                continue\n",
    "            \n",
    "            max_dist=max(dists[m] for m in track_j)\n",
    "                    \n",
    "            M[i,j]=max_dist\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METS (v1) takes 54.35s\n",
      "METS (v2) takes 57.07s\n",
      "ROW-TS takes 0.24s\n"
     ]
    }
   ],
   "source": [
    "#Choose map\n",
    "G=map_graph\n",
    "\n",
    "#Generate random paths to test\n",
    "from random import choice\n",
    "n_paths=10\n",
    "T=[]\n",
    "for i in range(n_paths):\n",
    "    orig=choice(list(G.nodes()))\n",
    "    dest=choice(list(G.nodes()))\n",
    "    T.append(nx.shortest_path(G, orig, dest, weight='length'))\n",
    "\n",
    "#Compute tha matrix\n",
    "import time\n",
    "t0=time.time()\n",
    "M_mets=matrix_element_similarity(G,T)\n",
    "t1=time.time()\n",
    "print(\"METS (v1) takes {:.2f}s\".format(t1-t0))\n",
    "t0=time.time()\n",
    "M_mets=matrix_element_similarity_v2(G,T)\n",
    "t1=time.time()\n",
    "print(\"METS (v2) takes {:.2f}s\".format(t1-t0))\n",
    "t0=time.time()\n",
    "M_rowts=row_wise_track_similarity(G,T)\n",
    "t1=time.time()\n",
    "print(\"ROW-TS takes {:.2f}s\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetrize(M,strategy='min'):\n",
    "    if strategy=='mean':\n",
    "        return (1/2)*(M+M.T)\n",
    "    if strategy=='min':\n",
    "        return np.minimum(M,M.T)\n",
    "    if strategy=='max':\n",
    "        return np.maximum(M,M.T)\n",
    "    raise KeyError(f'{strategy} is not a valid strategy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "def k_corridors_medoid_summarizer(M,k,T,**kwargs):\n",
    "    kmedoids = KMedoids(n_clusters=k, metric='precomputed', **kwargs) #For example random_state=0\n",
    "    kmedoids.fit(M) #M.T is not M!! WHICH ONE TO CHOOSE? :((\n",
    "\n",
    "    cluster_labels = kmedoids.labels_\n",
    "    medoid_indices = kmedoids.medoid_indices_\n",
    "    d=kmedoids.inertia_\n",
    "\n",
    "    k_corridors=[T[i] for i in medoid_indices]\n",
    "    return k_corridors,medoid_indices,cluster_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track converters from list of edges and lists of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges_to_nodes(track):\n",
    "    return [edge[0] for edge in track]\n",
    "\n",
    "def nodes_to_edges(track):\n",
    "    return [(track[i],track[i+1]) for i in range(len(track)-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pointwise metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_absolute_intersect(track_i,track_j):\n",
    "    \"\"\"\n",
    "    Returns 1 if there is at least one edge from track_i present in track_j,\n",
    "    and 0 otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    #Convert list of nodes into list of edges\n",
    "    set_i=set(nodes_to_edges(track_i))\n",
    "    set_j=set(nodes_to_edges(track_j))\n",
    "\n",
    "    #Calculate intesection\n",
    "    intersect=set_i.intersection(set_j)\n",
    "    n=len(intersect)\n",
    "    \n",
    "    return 0 if n==0 else 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_relative_intersect(track_i,track_j):\n",
    "    \"\"\"\n",
    "    Returns what portion of the edges from track_i are present in track_j\n",
    "    \"\"\"\n",
    "\n",
    "    #Convert list of nodes into list of edges\n",
    "    set_i=set(nodes_to_edges(track_i))\n",
    "    set_j=set(nodes_to_edges(track_j))\n",
    "\n",
    "    #Calculate intesection\n",
    "    intersect=set_i.intersection(set_j)\n",
    "    n=len(intersect)\n",
    "    \n",
    "    return n/len(set_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_lenght_relative_intersect(track_i,track_j,G):\n",
    "    \"\"\"\n",
    "    Returns what portion of the length of track_i is in the cummulative length of the edges\n",
    "    also present in track_j\n",
    "    \"\"\"\n",
    "\n",
    "    #Convert list of nodes into list of edges\n",
    "    set_i=set(nodes_to_edges(track_i))\n",
    "    set_j=set(nodes_to_edges(track_j))\n",
    "\n",
    "    #Calculate intersection\n",
    "    intersect=set_i.intersection(set_j)\n",
    "\n",
    "    l_intersect=sum([G.get_edge_data(*edge)[0]['length'] for edge in intersect])\n",
    "    l_i=sum([G.get_edge_data(*edge)[0]['length'] for edge in set_i])\n",
    "\n",
    "\n",
    "    \n",
    "    return l_intersect/l_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'k' metrics (applied to _all_ k corridors at once, not one by one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_absolute_intersect(track_i,k_tracks):\n",
    "    \"\"\"\n",
    "    Returns 1 if there is at least one edge from track_i present in k_tracks,\n",
    "    and 0 otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    #Convert list of nodes into list of edges\n",
    "    set_i=set(nodes_to_edges(track_i))\n",
    "\n",
    "    for track_j in k_tracks:\n",
    "        set_j=set(nodes_to_edges(track_j))\n",
    "\n",
    "        #Calculate intesection\n",
    "        intersect=set_i.intersection(set_j)\n",
    "        n=len(intersect)\n",
    "        if n!=1:\n",
    "            return 1\n",
    "    \n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_relative_intersect(track_i,k_tracks):\n",
    "    \"\"\"\n",
    "    Returns what portion of the edges from track_i are present in k_tracks\n",
    "    \"\"\"\n",
    "\n",
    "    #Convert list of nodes into list of edges\n",
    "    set_i=set(nodes_to_edges(track_i))\n",
    "    k_edges=np.concatenate([nodes_to_edges(track_j) for track_j in k_tracks])\n",
    "    set_j=set([(n1,n2) for n1,n2 in k_edges])\n",
    "\n",
    "    #Calculate intesection\n",
    "    intersect=set_i.intersection(set_j)\n",
    "    n=len(intersect)\n",
    "    \n",
    "    return n/len(set_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_lenght_relative_intersect(track_i,k_tracks,G):\n",
    "    \"\"\"\n",
    "    Returns what portion of the length of track_i is in the cummulative length of the edges\n",
    "    also present in k_tracks\n",
    "    \"\"\"\n",
    "\n",
    "    #Convert list of nodes into list of edges\n",
    "    set_i=set(nodes_to_edges(track_i))\n",
    "    k_edges=np.concatenate([nodes_to_edges(track_j) for track_j in k_tracks])\n",
    "    set_j=set([(n1,n2) for n1,n2 in k_edges])\n",
    "\n",
    "    #Calculate intersection\n",
    "    intersect=set_i.intersection(set_j)\n",
    "\n",
    "    l_intersect=sum([G.get_edge_data(*edge)[0]['length'] for edge in intersect])\n",
    "    l_i=sum([G.get_edge_data(*edge)[0]['length'] for edge in set_i])\n",
    "\n",
    "\n",
    "    \n",
    "    return l_intersect/l_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pointwise_metric(metric_fun,T,k_corridors,**kwargs):\n",
    "    \"\"\"\n",
    "    Returs the cummulative value (normalized by the number of tracks) of the \n",
    "    selected metric for the selected k corridors.\n",
    "    T: A list of tracks to be evaluated (if k_corridors are included they will also be evaluated)\n",
    "    k_corridors: A list of k selected corridors\n",
    "    metric_fun: The metric function to evaluate as metric_fun(T[i],k_corridors[j],**kwargs)\n",
    "    \"\"\"\n",
    "\n",
    "    result=0\n",
    "    for track_i in T:\n",
    "        for track_j in k_corridors:\n",
    "            result+=metric_fun(track_i,track_j,**kwargs)\n",
    "\n",
    "    result/=(len(T)*len(k_corridors))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_k_metric(metric_fun,T,k_corridors,**kwargs):\n",
    "    \"\"\"\n",
    "    Returs the cummulative value (normalized by the number of tracks) of the \n",
    "    selected metric for the selected k corridors.\n",
    "    T: A list of tracks to be evaluated (if k_corridors are included they will also be evaluated)\n",
    "    k_corridors: A list of k selected corridors\n",
    "    metric_fun: The metric function to evaluate as metric_fun(T[i],k_corridors[j],**kwargs)\n",
    "    \"\"\"\n",
    "\n",
    "    result=0\n",
    "    for track_i in T:\n",
    "        result+=metric_fun(track_i,k_corridors,**kwargs)\n",
    "\n",
    "    result/=len(T)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_M(G,T,cluster_labels,k_index,sym_strategy=None):\n",
    "#     M=row_wise_track_similarity(G,T)\n",
    "#     if sym_strategy:\n",
    "#         M=symmetrize(M,strategy=sym_strategy)\n",
    "\n",
    "#     d=0\n",
    "#     for i in range(len(k_index)):\n",
    "#         d+=M[cluster_labels==i,k_index[i]].sum() #TODO: Not always symetric! this or the other way?\n",
    "#     return d\n",
    "\n",
    "def evaluate_M(G,T,cluster_labels,k_index,sym_strategy=None):\n",
    "    M=row_wise_track_similarity(G,T)\n",
    "    if sym_strategy:\n",
    "        M=symmetrize(M,strategy=sym_strategy)\n",
    "\n",
    "    d=np.min(M[:,k_index],axis=1).sum()\n",
    "    return d\n",
    "\n",
    "def M_similarity(G,T,cluster_labels,k_index,include_corridors=False,ponderated=True,ponderation_k=1):\n",
    "    '''\n",
    "    This metric returns a metric based on the average similarity distance from\n",
    "    the tracks to the corridors.\n",
    "    If include_corridors, the average is made taking into consideration the corridors\n",
    "    as tracks too, otherwise the average is made using only the rest of the tracks.\n",
    "    \n",
    "    If ponderated, the result is ponderated so that the metric ranges (0,1],\n",
    "    where 1 means all tracks are corridors and 0 tracks are at an infinite distance from the corridors.\n",
    "    The ponderation is k/(k+d), where k is the ponderation parameter that defines at which d\n",
    "    the ponderated score is equal to 1/2\n",
    "    '''\n",
    "    d=evaluate_M(G,T,cluster_labels,k_index)\n",
    "    n=len(T)\n",
    "    if not include_corridors:\n",
    "        n-=len(k_index)\n",
    "    d/=n\n",
    "    if ponderated:\n",
    "        return ponderation_k/(ponderation_k+d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define sizes\n",
    "n_paths=100\n",
    "n_clusters=5\n",
    "\n",
    "#Choose map\n",
    "G=map_graph\n",
    "\n",
    "#Generate random paths to test\n",
    "from random import choice\n",
    "\n",
    "T=[]\n",
    "for i in range(n_paths):\n",
    "    orig=choice(list(G.nodes()))\n",
    "    dest=choice(list(G.nodes()))\n",
    "    T.append(nx.shortest_path(G, orig, dest, weight='length'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ROW-TS:\n",
      "\n",
      "\n",
      "------------------\n",
      "\tmean\t\n",
      "------------------\n",
      "\n",
      "Pointwise metrics:\n",
      "------------------\n",
      "Absolute intersection: 0.24\n",
      "Relative intersection: 0.0316\n",
      "Length intersection: 0.0297\n",
      "\n",
      "k-set metrics:\n",
      "--------------\n",
      "Absolute intersection: 1.00\n",
      "Relative intersection: 0.15\n",
      "Length intersection: 0.15\n",
      "\n",
      "M metrics:\n",
      "----------\n",
      "M average distance: 14m\n",
      "Ponderated M similarity: 0.0673\n",
      "\n",
      "\n",
      "------------------\n",
      "\tmin\t\n",
      "------------------\n",
      "\n",
      "Pointwise metrics:\n",
      "------------------\n",
      "Absolute intersection: 0.28\n",
      "Relative intersection: 0.0587\n",
      "Length intersection: 0.0607\n",
      "\n",
      "k-set metrics:\n",
      "--------------\n",
      "Absolute intersection: 1.00\n",
      "Relative intersection: 0.27\n",
      "Length intersection: 0.29\n",
      "\n",
      "M metrics:\n",
      "----------\n",
      "M average distance: 30m\n",
      "Ponderated M similarity: 0.0319\n",
      "\n",
      "\n",
      "------------------\n",
      "\tmax\t\n",
      "------------------\n",
      "\n",
      "Pointwise metrics:\n",
      "------------------\n",
      "Absolute intersection: 0.32\n",
      "Relative intersection: 0.0354\n",
      "Length intersection: 0.0307\n",
      "\n",
      "k-set metrics:\n",
      "--------------\n",
      "Absolute intersection: 1.00\n",
      "Relative intersection: 0.13\n",
      "Length intersection: 0.12\n",
      "\n",
      "M metrics:\n",
      "----------\n",
      "M average distance: 22m\n",
      "Ponderated M similarity: 0.0427\n"
     ]
    }
   ],
   "source": [
    "#Compute the similarity matrix\n",
    "M_rowts=row_wise_track_similarity(G,T)\n",
    "\n",
    "\n",
    "k_corridors,k_index,cluster_labels=k_corridors_medoid_summarizer(M_rowts,n_clusters,T,random_state=0)\n",
    "\n",
    "print(\"For ROW-TS:\")\n",
    "\n",
    "for sym_strategy in [\"mean\",\"min\",\"max\"]:\n",
    "    #Symmetrize M\n",
    "    M=symmetrize(M_rowts,strategy=sym_strategy)\n",
    "    #Cluster in k corridors\n",
    "    k_corridors,k_index,cluster_labels=k_corridors_medoid_summarizer(M,n_clusters,T,random_state=0)\n",
    "\n",
    "    #Test performance\n",
    "\n",
    "    print(f'\\n\\n------------------\\n\\t{sym_strategy}\\t\\n------------------')\n",
    "\n",
    "    print(\"\\nPointwise metrics:\\n------------------\")\n",
    "\n",
    "    abs_inter=evaluate_pointwise_metric(pointwise_absolute_intersect,T,k_corridors)\n",
    "    print(\"Absolute intersection: {:.2f}\".format(abs_inter))\n",
    "\n",
    "    rel_inter=evaluate_pointwise_metric(pointwise_relative_intersect,T,k_corridors)\n",
    "    print(\"Relative intersection: {:.4f}\".format(rel_inter))\n",
    "\n",
    "    l_rel_inter=evaluate_pointwise_metric(pointwise_lenght_relative_intersect,T,k_corridors,G=G)\n",
    "    print(\"Length intersection: {:.4f}\".format(l_rel_inter))\n",
    "\n",
    "    print(\"\\nk-set metrics:\\n--------------\")\n",
    "\n",
    "    abs_inter=evaluate_k_metric(k_absolute_intersect,T,k_corridors)\n",
    "    print(\"Absolute intersection: {:.2f}\".format(abs_inter))\n",
    "\n",
    "    rel_inter=evaluate_k_metric(k_relative_intersect,T,k_corridors)\n",
    "    print(\"Relative intersection: {:.2f}\".format(rel_inter))\n",
    "\n",
    "    l_rel_inter=evaluate_k_metric(k_lenght_relative_intersect,T,k_corridors,G=G)\n",
    "    print(\"Length intersection: {:.2f}\".format(l_rel_inter))\n",
    "\n",
    "    print(\"\\nM metrics:\\n----------\")\n",
    "\n",
    "    m_sim=M_similarity(G,T,cluster_labels,k_index,ponderated=False,include_corridors=True)\n",
    "    print(\"M average distance: {:.0f}m\".format(m_sim))\n",
    "\n",
    "    m_sim=M_similarity(G,T,cluster_labels,k_index,ponderated=True,include_corridors=True)\n",
    "    print(\"Ponderated M similarity: {:.4f}\".format(m_sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test best symetrization strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Intermediate result: 25 paths, 5 clusters\n",
      "None: 0.257±0.025\tmean: 0.301±0.031\tmin: 0.323±0.040\tmax: 0.308±0.040\t\n",
      "\n",
      "Intermediate result: 50 paths, 5 clusters\n",
      "None: 0.134±0.020\tmean: 0.213±0.027\tmin: 0.233±0.038\tmax: 0.217±0.025\t\n",
      "\n",
      "Intermediate result: 100 paths, 5 clusters\n",
      "None: 0.090±0.017\tmean: 0.165±0.040\tmin: 0.215±0.059\tmax: 0.164±0.024\t\n",
      "\n",
      "Global results:\n",
      "None: 0.161±0.074\tmean: 0.226±0.066\tmin: 0.257±0.066\tmax: 0.230±0.067\t"
     ]
    }
   ],
   "source": [
    "n_paths_clusters_list=[(25,5),(50,5),(100,5)]\n",
    "n_experiments=10\n",
    "\n",
    "G=map_graph\n",
    "\n",
    "strategies=[None,\"mean\",\"min\",\"max\"]\n",
    "results={s:[] for s in strategies}\n",
    "\n",
    "from random import choice\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for n_paths,n_clusters in n_paths_clusters_list:\n",
    "    print(f\"\\n\\nIntermediate result: {n_paths} paths, {n_clusters} clusters\")\n",
    "    iter_results={s:[] for s in strategies}\n",
    "    for strategy in strategies:\n",
    "        for i in range(n_experiments):\n",
    "            T=[]\n",
    "            for i in range(n_paths):\n",
    "                orig=choice(list(G.nodes()))\n",
    "                dest=choice(list(G.nodes()))\n",
    "                T.append(nx.shortest_path(G, orig, dest, weight='length'))\n",
    "\n",
    "            M=row_wise_track_similarity(G,T)\n",
    "            if strategy:\n",
    "                M=symmetrize(M,strategy=strategy)\n",
    "            k_corridors,k_index,cluster_labels=k_corridors_medoid_summarizer(M,n_clusters,T)\n",
    "            try:\n",
    "                l_rel_inter=evaluate_k_metric(k_lenght_relative_intersect,T,k_corridors,G=G)\n",
    "            except ZeroDivisionError:\n",
    "                continue\n",
    "\n",
    "            iter_results[strategy].append(l_rel_inter)\n",
    "    for s,v in iter_results.items():\n",
    "        print(f'{s}: {np.mean(v):.3f}±{np.std(v):.3f}',end=\"\\t\")\n",
    "        results[s]+=v\n",
    "print(\"\\n\\nGlobal results:\")\n",
    "for s,v in results.items():\n",
    "        print(f'{s}: {np.mean(v):.3f}±{np.std(v):.3f}',end=\"\\t\")\n",
    "warnings.filterwarnings('default')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
